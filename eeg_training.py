# -*- coding: utf-8 -*-
"""EEG_Training

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FMOOK8oOzqg5u_xUpG7E_yi7c-LPtzSZ
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/EEG_Project

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %ls

# !unzip "/content/drive/MyDrive/EEG_Project/dataset.zip"

# Commented out IPython magic to ensure Python compatibility.
from keras.preprocessing.image import ImageDataGenerator
#these libraries are going to help in the model building.
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization
from keras.layers import Activation, Dropout, Flatten, Dense


import matplotlib.pyplot as plt 
import matplotlib.image as mpimg
# %matplotlib inline

# dimensions of our images.
img_width, img_height = 32, 32

#setting up the directories
train_data_dir = '/content/drive/MyDrive/EEG_Project/train/train'
validation_data_dir = '/content/drive/MyDrive/EEG_Project/train/validation'

#setting up the batchsizes.

#below are the hyerparameters
epochs = 5
batch_size = 32

input_shape = (img_width, img_height, 3)

# this is the augmentation configuration we will use for training
# augumentation generates more training images by rescaling, shearing, etc
train_datagen = ImageDataGenerator(
    rescale=1./ 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

#this generates batches of augment data for training
train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='binary')

# this is the augmentation configuration we will use for validating
val_datagen = ImageDataGenerator(rescale=1./255)

#this generates batches of augment data for validating
validation_generator = val_datagen.flow_from_directory(
    validation_data_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    class_mode='binary')

model = Sequential()

model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
#for extracting more features, I am adding more number of convolutional layers.
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

#flatten converts the image matrix to a 1-D vector.
model.add(Flatten())

model.add(Dense(512, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))
#below dense function manages the output neuron.
model.add(Dense(1, activation='sigmoid'))

model.summary()

#configuring the model
model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

#to print a summary representation of your model
model.summary()

batch_size = 32

from keras.callbacks import ModelCheckpoint

callbacks= [ModelCheckpoint('model_normal.h5', save_weights_only=False, save_best_only=True, verbose=1)]

#model training
history=model.fit(
    train_generator,
   
    epochs=epochs,
    validation_data=validation_generator,
     callbacks=callbacks
    )

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

